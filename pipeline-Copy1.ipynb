{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sc\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s&amp;p500_close</th>\n",
       "      <th>s&amp;p500_volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-08-31</th>\n",
       "      <td>1473.989990</td>\n",
       "      <td>2731610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-09-04</th>\n",
       "      <td>1489.420044</td>\n",
       "      <td>2766600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-09-05</th>\n",
       "      <td>1472.290039</td>\n",
       "      <td>2991600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-09-06</th>\n",
       "      <td>1478.550049</td>\n",
       "      <td>2459590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-09-07</th>\n",
       "      <td>1453.550049</td>\n",
       "      <td>3191080000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           s&p500_close  s&p500_volume\n",
       "Date                                  \n",
       "2007-08-31  1473.989990     2731610000\n",
       "2007-09-04  1489.420044     2766600000\n",
       "2007-09-05  1472.290039     2991600000\n",
       "2007-09-06  1478.550049     2459590000\n",
       "2007-09-07  1453.550049     3191080000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ALL INDICES READ INTO DF\n",
    "\n",
    "from collections import OrderedDict\n",
    "series = OrderedDict()\n",
    "for filename in os.listdir(\"datasets/indices/\"):\n",
    "    \n",
    "    path = \"datasets/indices/\" + filename\n",
    "    cols = ['Date', 'Close', 'Volume']\n",
    "    col1 = str(filename.lower().split(\".\")[0] + '_close')\n",
    "    col2 = str(filename.lower().split(\".\")[0] + '_volume')\n",
    "    \n",
    "    try:\n",
    "        series[filename] = pd.read_csv(path, parse_dates=True, header=0, index_col=0, usecols=cols)\n",
    "        series[filename] = series[filename].rename(columns={'Date':'date','Close':col1,'Volume':col2})\n",
    "    except:\n",
    "        pass\n",
    "    #    if filename == \"S&P500-Energy.csv\":\n",
    "    #        series[filename] = pd.read_csv(path, parse_dates=True, header=0, index_col=0, usecols=['Date','Close'])\n",
    "    #        series[filename] = series[filename].rename(columns={'Date':'date','Close':col1})\n",
    "\n",
    "df_indices = pd.DataFrame()\n",
    "for each in series.keys():\n",
    "    df_indices = pd.concat([df_indices, series[each]], axis=1).dropna()\n",
    "df_indices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abb_sentiment</th>\n",
       "      <th>abb_newsvol</th>\n",
       "      <th>abb_buzz</th>\n",
       "      <th>asys_sentiment</th>\n",
       "      <th>asys_newsvol</th>\n",
       "      <th>asys_buzz</th>\n",
       "      <th>ccgi_sentiment</th>\n",
       "      <th>ccgi_newsvol</th>\n",
       "      <th>ccgi_buzz</th>\n",
       "      <th>cenx_sentiment</th>\n",
       "      <th>...</th>\n",
       "      <th>cmi_buzz</th>\n",
       "      <th>fslr_sentiment</th>\n",
       "      <th>fslr_newsvol</th>\n",
       "      <th>fslr_buzz</th>\n",
       "      <th>ge_sentiment</th>\n",
       "      <th>ge_newsvol</th>\n",
       "      <th>ge_buzz</th>\n",
       "      <th>tsla_sentiment</th>\n",
       "      <th>tsla_newsvol</th>\n",
       "      <th>tsla_buzz</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            abb_sentiment abb_newsvol  abb_buzz  asys_sentiment asys_newsvol  \\\n",
       "Date                                                                           \n",
       "2013-01-01            0.0         0.0       0.0             0.0          0.0   \n",
       "2013-01-02            0.0         0.0       0.0             0.0          0.0   \n",
       "2013-01-03            0.0         0.0       0.0             0.0          0.0   \n",
       "2013-01-04            0.0         0.0       0.0             0.0          0.0   \n",
       "2013-01-05            0.0         0.0       0.0             0.0          0.0   \n",
       "\n",
       "            asys_buzz  ccgi_sentiment ccgi_newsvol  ccgi_buzz  cenx_sentiment  \\\n",
       "Date                                                                            \n",
       "2013-01-01        0.0             0.0            0        0.0             0.0   \n",
       "2013-01-02        0.0             0.0            0        0.0             0.0   \n",
       "2013-01-03        0.0             0.0            0        0.0            -5.0   \n",
       "2013-01-04        0.0             0.0            0        0.0             0.0   \n",
       "2013-01-05        0.0             0.0            0        0.0             0.0   \n",
       "\n",
       "              ...    cmi_buzz  fslr_sentiment  fslr_newsvol fslr_buzz  \\\n",
       "Date          ...                                                       \n",
       "2013-01-01    ...         0.0             0.0           0.0       0.0   \n",
       "2013-01-02    ...        10.0            -1.0           4.0      10.0   \n",
       "2013-01-03    ...         2.0             5.0           2.0       5.0   \n",
       "2013-01-04    ...         5.0            -1.0           3.0       7.0   \n",
       "2013-01-05    ...         0.0             0.0           0.0       0.0   \n",
       "\n",
       "            ge_sentiment  ge_newsvol ge_buzz  tsla_sentiment  tsla_newsvol  \\\n",
       "Date                                                                         \n",
       "2013-01-01           1.0        10.0    10.0             0.0           0.0   \n",
       "2013-01-02           3.0        19.0    10.0             0.0           0.0   \n",
       "2013-01-03           2.0         9.0     4.0             0.0           0.0   \n",
       "2013-01-04           3.0         7.0     3.0             0.0           0.0   \n",
       "2013-01-05           3.0         1.0     0.0             0.0           0.0   \n",
       "\n",
       "           tsla_buzz  \n",
       "Date                  \n",
       "2013-01-01       0.0  \n",
       "2013-01-02       0.0  \n",
       "2013-01-03       0.0  \n",
       "2013-01-04       0.0  \n",
       "2013-01-05       0.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ALL SENTIMENT DATA READ INTO DF\n",
    "\n",
    "series = OrderedDict()\n",
    "for filename in os.listdir(\"datasets/sentiment/\"):\n",
    "    \n",
    "    path = \"datasets/sentiment/\" + filename\n",
    "    cols = ['Date', 'Sentiment', 'News Volume', 'News Buzz']\n",
    "    col1 = str(filename[4:].lower().split(\"_\")[0] + '_sentiment')\n",
    "    col2 = str(filename[4:].lower().split(\"_\")[0] + '_newsvol')\n",
    "    col3 = str(filename[4:].lower().split(\"_\")[0] + '_buzz')\n",
    "    \n",
    "    try:\n",
    "        series[filename] = pd.read_csv(path, parse_dates=True, header=0, index_col=0, usecols=cols)\n",
    "        series[filename] = series[filename].rename(columns={'Date':'date','Sentiment':col1,'News Volume':col2, 'News Buzz':col3})\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "df_sentiment = pd.DataFrame()\n",
    "for each in series.keys():\n",
    "    df_sentiment = pd.concat([df_sentiment, series[each]], axis=1).dropna()\n",
    "df_sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abb_close</th>\n",
       "      <th>abb_volume</th>\n",
       "      <th>asys_close</th>\n",
       "      <th>asys_volume</th>\n",
       "      <th>ccgi_close</th>\n",
       "      <th>ccgi_volume</th>\n",
       "      <th>cenx_close</th>\n",
       "      <th>cenx_volume</th>\n",
       "      <th>cmi_close</th>\n",
       "      <th>cmi_volume</th>\n",
       "      <th>fslr_close</th>\n",
       "      <th>fslr_volume</th>\n",
       "      <th>ge_close</th>\n",
       "      <th>ge_volume</th>\n",
       "      <th>pcrfy_close</th>\n",
       "      <th>pcrfy_volume</th>\n",
       "      <th>tsla_close</th>\n",
       "      <th>tsla_volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-06-29</th>\n",
       "      <td>17.490000</td>\n",
       "      <td>4731000.0</td>\n",
       "      <td>8.270000</td>\n",
       "      <td>47400.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.070000</td>\n",
       "      <td>4079400.0</td>\n",
       "      <td>66.239998</td>\n",
       "      <td>4498100.0</td>\n",
       "      <td>114.419998</td>\n",
       "      <td>2243400.0</td>\n",
       "      <td>14.480000</td>\n",
       "      <td>114904900.0</td>\n",
       "      <td>12.470000</td>\n",
       "      <td>467600.0</td>\n",
       "      <td>23.889999</td>\n",
       "      <td>18766300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30</th>\n",
       "      <td>17.280001</td>\n",
       "      <td>4224600.0</td>\n",
       "      <td>8.350000</td>\n",
       "      <td>12800.0</td>\n",
       "      <td>42.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.830000</td>\n",
       "      <td>3519600.0</td>\n",
       "      <td>65.129997</td>\n",
       "      <td>3268500.0</td>\n",
       "      <td>113.830002</td>\n",
       "      <td>1937300.0</td>\n",
       "      <td>14.420000</td>\n",
       "      <td>81568200.0</td>\n",
       "      <td>12.530000</td>\n",
       "      <td>201000.0</td>\n",
       "      <td>23.830000</td>\n",
       "      <td>17187100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-01</th>\n",
       "      <td>17.590000</td>\n",
       "      <td>6328900.0</td>\n",
       "      <td>8.710000</td>\n",
       "      <td>70400.0</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.680000</td>\n",
       "      <td>3968000.0</td>\n",
       "      <td>64.820000</td>\n",
       "      <td>5136200.0</td>\n",
       "      <td>117.449997</td>\n",
       "      <td>2078200.0</td>\n",
       "      <td>14.120000</td>\n",
       "      <td>107077700.0</td>\n",
       "      <td>12.430000</td>\n",
       "      <td>342500.0</td>\n",
       "      <td>21.959999</td>\n",
       "      <td>8218800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-02</th>\n",
       "      <td>17.430000</td>\n",
       "      <td>2315300.0</td>\n",
       "      <td>8.590000</td>\n",
       "      <td>41200.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>2444000.0</td>\n",
       "      <td>64.239998</td>\n",
       "      <td>3766900.0</td>\n",
       "      <td>120.519997</td>\n",
       "      <td>2082800.0</td>\n",
       "      <td>13.880000</td>\n",
       "      <td>78544600.0</td>\n",
       "      <td>12.450000</td>\n",
       "      <td>157800.0</td>\n",
       "      <td>19.200001</td>\n",
       "      <td>5139800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-06</th>\n",
       "      <td>17.690001</td>\n",
       "      <td>2955000.0</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>30600.0</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.610000</td>\n",
       "      <td>3302200.0</td>\n",
       "      <td>63.570000</td>\n",
       "      <td>3913900.0</td>\n",
       "      <td>121.879997</td>\n",
       "      <td>2506700.0</td>\n",
       "      <td>13.970000</td>\n",
       "      <td>77154700.0</td>\n",
       "      <td>12.810000</td>\n",
       "      <td>247400.0</td>\n",
       "      <td>16.110001</td>\n",
       "      <td>6866900.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            abb_close  abb_volume asys_close  asys_volume ccgi_close  \\\n",
       "Date                                                                   \n",
       "2010-06-29  17.490000   4731000.0   8.270000      47400.0  45.000000   \n",
       "2010-06-30  17.280001   4224600.0   8.350000      12800.0  42.500000   \n",
       "2010-07-01  17.590000   6328900.0   8.710000      70400.0  44.500000   \n",
       "2010-07-02  17.430000   2315300.0   8.590000      41200.0  45.000000   \n",
       "2010-07-06  17.690001   2955000.0   8.600000      30600.0  37.500000   \n",
       "\n",
       "            ccgi_volume cenx_close  cenx_volume  cmi_close  cmi_volume  \\\n",
       "Date                                                                     \n",
       "2010-06-29          0.0   9.070000    4079400.0  66.239998   4498100.0   \n",
       "2010-06-30          0.0   8.830000    3519600.0  65.129997   3268500.0   \n",
       "2010-07-01          0.0   8.680000    3968000.0  64.820000   5136200.0   \n",
       "2010-07-02          0.0   8.600000    2444000.0  64.239998   3766900.0   \n",
       "2010-07-06          0.0   8.610000    3302200.0  63.570000   3913900.0   \n",
       "\n",
       "            fslr_close  fslr_volume   ge_close    ge_volume pcrfy_close  \\\n",
       "Date                                                                      \n",
       "2010-06-29  114.419998    2243400.0  14.480000  114904900.0   12.470000   \n",
       "2010-06-30  113.830002    1937300.0  14.420000   81568200.0   12.530000   \n",
       "2010-07-01  117.449997    2078200.0  14.120000  107077700.0   12.430000   \n",
       "2010-07-02  120.519997    2082800.0  13.880000   78544600.0   12.450000   \n",
       "2010-07-06  121.879997    2506700.0  13.970000   77154700.0   12.810000   \n",
       "\n",
       "            pcrfy_volume tsla_close  tsla_volume  \n",
       "Date                                              \n",
       "2010-06-29      467600.0  23.889999   18766300.0  \n",
       "2010-06-30      201000.0  23.830000   17187100.0  \n",
       "2010-07-01      342500.0  21.959999    8218800.0  \n",
       "2010-07-02      157800.0  19.200001    5139800.0  \n",
       "2010-07-06      247400.0  16.110001    6866900.0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ALL STOCKS READ INTO DF\n",
    "\n",
    "series = OrderedDict()\n",
    "for filename in os.listdir(\"datasets/stock prices/\"):\n",
    "    \n",
    "    path = \"datasets/stock prices/\" + filename\n",
    "    cols = ['Date', 'Close', 'Volume']\n",
    "    col1 = str(filename.lower().split(\".\")[0] + '_close')\n",
    "    col2 = str(filename.lower().split(\".\")[0] + '_volume')\n",
    "    \n",
    "    try:\n",
    "        series[filename] = pd.read_csv(path, parse_dates=True, header=0, index_col=0, usecols=cols)\n",
    "        series[filename] = series[filename].rename(columns={'Date':'date','Close':col1,'Volume':col2})\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "df_stocks = pd.DataFrame()\n",
    "for each in series.keys():\n",
    "    df_stocks = pd.concat([df_stocks, series[each]], axis=1).dropna()\n",
    "df_stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xrange' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-4d62e7a2e40c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_cols\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'close'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_pre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mmat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xrange' is not defined"
     ]
    }
   ],
   "source": [
    "# CONVERTING TO LOG RETURNS\n",
    "\n",
    "df_pre = pd.concat([df_stocks, df_indices],axis=1).dropna()\n",
    "\n",
    "# Stashing column names\n",
    "all_cols = df_pre.columns\n",
    "\n",
    "prices = [k for k in all_cols if 'close' in k]\n",
    "mat = df_pre[prices].as_matrix()\n",
    "for i in xrange(len(mat)):\n",
    "    mat[i+1] = mat[i+1] - mat[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# FINAL MERGE\n",
    "\n",
    "df = pd.concat([df_stocks, df_sentiment],axis=1).dropna()\n",
    "df = pd.concat([df, df_indices],axis=1).dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abb_close</th>\n",
       "      <th>asys_close</th>\n",
       "      <th>ccgi_close</th>\n",
       "      <th>cenx_close</th>\n",
       "      <th>cmi_close</th>\n",
       "      <th>fslr_close</th>\n",
       "      <th>ge_close</th>\n",
       "      <th>pcrfy_close</th>\n",
       "      <th>tsla_close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-06-29</th>\n",
       "      <td>17.490000</td>\n",
       "      <td>8.270000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>9.070000</td>\n",
       "      <td>66.239998</td>\n",
       "      <td>114.419998</td>\n",
       "      <td>14.480000</td>\n",
       "      <td>12.470000</td>\n",
       "      <td>23.889999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30</th>\n",
       "      <td>17.280001</td>\n",
       "      <td>8.350000</td>\n",
       "      <td>42.500000</td>\n",
       "      <td>8.830000</td>\n",
       "      <td>65.129997</td>\n",
       "      <td>113.830002</td>\n",
       "      <td>14.420000</td>\n",
       "      <td>12.530000</td>\n",
       "      <td>23.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-01</th>\n",
       "      <td>17.590000</td>\n",
       "      <td>8.710000</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>8.680000</td>\n",
       "      <td>64.820000</td>\n",
       "      <td>117.449997</td>\n",
       "      <td>14.120000</td>\n",
       "      <td>12.430000</td>\n",
       "      <td>21.959999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-02</th>\n",
       "      <td>17.430000</td>\n",
       "      <td>8.590000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>64.239998</td>\n",
       "      <td>120.519997</td>\n",
       "      <td>13.880000</td>\n",
       "      <td>12.450000</td>\n",
       "      <td>19.200001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-06</th>\n",
       "      <td>17.690001</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>8.610000</td>\n",
       "      <td>63.570000</td>\n",
       "      <td>121.879997</td>\n",
       "      <td>13.970000</td>\n",
       "      <td>12.810000</td>\n",
       "      <td>16.110001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            abb_close asys_close ccgi_close cenx_close  cmi_close  fslr_close  \\\n",
       "Date                                                                            \n",
       "2010-06-29  17.490000   8.270000  45.000000   9.070000  66.239998  114.419998   \n",
       "2010-06-30  17.280001   8.350000  42.500000   8.830000  65.129997  113.830002   \n",
       "2010-07-01  17.590000   8.710000  44.500000   8.680000  64.820000  117.449997   \n",
       "2010-07-02  17.430000   8.590000  45.000000   8.600000  64.239998  120.519997   \n",
       "2010-07-06  17.690001   8.600000  37.500000   8.610000  63.570000  121.879997   \n",
       "\n",
       "             ge_close pcrfy_close tsla_close  \n",
       "Date                                          \n",
       "2010-06-29  14.480000   12.470000  23.889999  \n",
       "2010-06-30  14.420000   12.530000  23.830000  \n",
       "2010-07-01  14.120000   12.430000  21.959999  \n",
       "2010-07-02  13.880000   12.450000  19.200001  \n",
       "2010-07-06  13.970000   12.810000  16.110001  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DATAFRAME OF ONLY STOCK TICKS\n",
    "\n",
    "series_ticks = OrderedDict()\n",
    "for filename in os.listdir(\"datasets/stock prices/\"):\n",
    "    \n",
    "    path = \"datasets/stock prices/\" + filename\n",
    "    cols = ['Date', 'Close']\n",
    "    col1 = str(filename.lower().split(\".\")[0] + '_close')    \n",
    "    try:\n",
    "        series_ticks[filename] = pd.read_csv(path, parse_dates=True, header=0, index_col=0, usecols=cols)\n",
    "        series_ticks[filename] = series_ticks[filename].rename(columns={'Date':'date','Close':col1})\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "df_ticks = pd.DataFrame()\n",
    "for each in series_ticks.keys():\n",
    "    df_ticks = pd.concat([df_ticks, series_ticks[each]], axis=1).dropna()\n",
    "df_ticks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series abb_close is  nonstationary\n",
      "Time Series asys_close is  nonstationary\n",
      "Time Series ccgi_closeis stationary\n",
      "Time Series cenx_close is  nonstationary\n",
      "Time Series cmi_close is  nonstationary\n",
      "Time Series fslr_close is  nonstationary\n",
      "Time Series ge_close is  nonstationary\n",
      "Time Series pcrfy_close is  nonstationary\n",
      "Time Series tsla_close is  nonstationary\n"
     ]
    }
   ],
   "source": [
    "#NON-STATIONARITY CHECK\n",
    "import statsmodels as sm\n",
    "import numpy as np\n",
    "\n",
    "for col in df_ticks:\n",
    "    d_order0=sm.tsa.stattools.adfuller(df_ticks[col].astype(float))\n",
    "#     print('adf: ', d_order0[0])\n",
    "#     print('p-value: ', d_order0[1])\n",
    "#     print('Critical values: ', d_order0[4])\n",
    "\n",
    "    if d_order0[0]> d_order0[4]['5%']: \n",
    "        print('Time Series ' + col +' is  nonstationary')\n",
    "#         print(d)\n",
    "    else:\n",
    "        print('Time Series ' + col + 'is stationary')\n",
    "#         print(d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1805, 1)\n",
      "(1805, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-008d3beae732>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1172\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=np.float64,\n\u001b[1;32m   1173\u001b[0m                          order=\"C\")\n\u001b[0;32m-> 1174\u001b[0;31m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1175\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    170\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[1;32m    171\u001b[0m             'multilabel-indicator', 'multilabel-sequences']:\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "lr = linear_model.LogisticRegression()\n",
    "a = np.arange(len(df_ticks)).reshape((len(df_ticks),1))\n",
    "b = df_ticks[\"abb_close\"].astype(float).as_matrix().reshape((len(df_ticks),1))\n",
    "print (a.shape)\n",
    "print (b.shape)\n",
    "lr.fit(a,b)\n",
    "pr = lr.predict(b)\n",
    "plt.fig()\n",
    "df_ticks[\"abb_close\"].astype(float).plot()\n",
    "pr.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series abb_close is  nonstationary\n",
      "Time Series asys_close is  nonstationary\n",
      "Time Series ccgi_closeis stationary\n",
      "Time Series cenx_close is  nonstationary\n",
      "Time Series cmi_close is  nonstationary\n",
      "Time Series fslr_close is  nonstationary\n",
      "Time Series ge_close is  nonstationary\n",
      "Time Series pcrfy_close is  nonstationary\n",
      "Time Series tsla_close is  nonstationary\n"
     ]
    }
   ],
   "source": [
    "from scipy import signal\n",
    "from pandas import Series\n",
    "\n",
    "for col in df_ticks:\n",
    "    d_order0=sm.tsa.stattools.adfuller(Series(signal.detrend(df_ticks[col].astype(float))))\n",
    "    if d_order0[0]> d_order0[4]['5%']: \n",
    "        print('Time Series ' + col +' is  nonstationary')\n",
    "#         print(d)\n",
    "    else:\n",
    "        print('Time Series ' + col + 'is stationary')\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
